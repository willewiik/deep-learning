{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8SC3p-UCusw"
   },
   "source": [
    "# RNN Machine Translation Laboration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvKNkEYrCusy"
   },
   "source": [
    "In this lab, your task is to build a sequence-to-sequence model, using recurrent neural networks, that translates short sentences from Swedish into English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Tensorflow is quite chatty; filter out warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "IDNS-GhLCusz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that Tensorflow uses a GPU _(optional)_\n",
    "\n",
    "Training the models in this notebook can be sped up significantly with a GPU.  The following cell can be used to check if the GPU is set up correctly.  If you run on CPU, you can either run or just ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úó Tensorflow has NOT detected a GPU.\n",
      "\n",
      "For GPU support, visit: <https://www.tensorflow.org/install/pip>\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "if tf.config.list_physical_devices(\"GPU\"):\n",
    "    print(\"‚úì Tensorflow has detected a GPU.\")\n",
    "    import shutil\n",
    "    if not shutil.which(\"ptxas\"):\n",
    "        print(\"\\n‚úó Command 'ptxas' not found in path -- you might have to install `cudatoolkit-dev`\")\n",
    "    if not \"XLA_FLAGS\" in os.environ:\n",
    "        print(\"\\n‚úó XLA_FLAGS not set. If you encounter errors during training, you might have to set\")\n",
    "        print(\"        XLA_FLAGS=\\\"--xla_gpu_cuda_data_dir=$CONDA_PREFIX/lib/\\\"\")\n",
    "    \n",
    "    # Allow growth of GPU memory, otherwise it will always look like all the memory is being used\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
    "else:\n",
    "    print(\"‚úó Tensorflow has NOT detected a GPU.\")\n",
    "    print()\n",
    "    print(\"For GPU support, visit: <https://www.tensorflow.org/install/pip>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Specification\n",
    "\n",
    "Your task in this assignment is to:\n",
    "\n",
    "1. Build an encoder‚Äîdecoder model based on recurrent neural networks.\n",
    "2. Train this model on the provided training data, a collection of parallel Swedish‚ÄìEnglish sentences.\n",
    "3. Evaluate the performance of this model on the provided test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX-5kU7mCus1"
   },
   "source": [
    "### The data: Swedish‚ÄìEnglish Anki corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luSjyoOqCus2"
   },
   "source": [
    "The data in this lab consists of bilingual Swedish‚ÄìEnglish sentence pairs from the [Tatoeba Project](https://tatoeba.org/en) as collected by [Anki](http://www.manythings.org/anki/).  These are comparatively short sentences, suitable for language learners, and therefore also well-suited for building a small machine translation model. Here are some example sentences from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EaFUyzF-Cus2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i returned to japan .', 'jag √•terv√§nde till japan .']\n",
      "['i love her .', 'jag √§lskar henne .']\n",
      "[\"this is tom ' s school .\", 'detta √§r toms skola .']\n",
      "['i can hardly stand .', 'jag kan knappt st√• .']\n"
     ]
    }
   ],
   "source": [
    "with open(\"en-sv-train.txt\", \"rt\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        pair = [sent for sent in line.rstrip().split(\"\\t\")]\n",
    "        print(pair)\n",
    "        if i > 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVYZFLVyCus3"
   },
   "source": [
    "Each line in the data files consists of an English‚ÄìSwedish sentence pair. The sentences are already lower-cased and pre-tokenized (using the [toktok tokenizer from NLTK](https://www.nltk.org/howto/tokenize.html)), so we can simply split them up by whitespace to get sequences of tokens.  To make your life a bit easier, we have removed sentences longer than 15 words. \n",
    "\n",
    "The next cell contains code that yields the sentences contained in a file as lists of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Eay_PCwACus4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'returned', 'to', 'japan', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENGLISH = 0\n",
    "SWEDISH = 1\n",
    "\n",
    "def sentences(filename, idx):\n",
    "    # Use idx=0 for English, idx=1 for Swedish\n",
    "    with open(filename, \"rt\", encoding=\"utf8\") as source:\n",
    "        for line in source:\n",
    "            yield line.rstrip().split(\"\\t\")[idx].split()\n",
    "\n",
    "# Example usage\n",
    "next(sentences(\"en-sv-train.txt\", ENGLISH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ypi63gGlCus5"
   },
   "source": [
    "## Part 1: Build the vocabularies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REbT89KqCus5"
   },
   "source": [
    "Before we can feed them into any model, we first need to convert the text strings to integers. For this purpose, we'll create a **vocabulary** of tokens that are known to the model, one vocabulary for each language. We need four **special tokens (or \"pseudowords\")**:\n",
    "\n",
    "1. `<pad>` at index 0 for padding purposes\n",
    "2. `<unk>` at index 1 to represent unknown words\n",
    "3. `<bos>` at index 2 to mark the \"beginning of sequence\" in the decoder\n",
    "4. `<eos>` at index 3 to mark the \"end of sequence\" in the decoder\n",
    "\n",
    "The remaining items in the vocabulary should be made up of the **most frequent words** in the training data for the respective language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ü§î Task 1: Write the function to build the vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "R29hmyaRCus5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def make_vocab(sentences, max_size):    \n",
    "    \"\"\"Return a list of the `max_size` most frequent tokens in `sentences`.\"\"\"\n",
    "    \n",
    "    # Needs to be the four first values (from test under)\n",
    "    vocabulary = ['<pad>', '<unk>', '<bos>', '<eos>']\n",
    "    \n",
    "    \n",
    "    #####################################################\n",
    "    # HAD TO ADD ENCODING =\"utf8\" to function sentences #\n",
    "    #####################################################\n",
    "    \n",
    "    cnt = Counter()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            cnt[word] += 1\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    # 2+3 (automatically sorted for us)\n",
    "    # Returns list of tuples [(key, value), (key, value), ...]\n",
    "    common_words = cnt.most_common(max_size-4)\n",
    "    # Remake to dictionary to extract keys to list. \n",
    "    common_words = list(dict(common_words).keys())\n",
    "    \n",
    "    \n",
    "    # 4\n",
    "    vocabulary += common_words\n",
    "    return(vocabulary)\n",
    "    \n",
    "    \n",
    "    # TODO\n",
    "    # 1. Count of how often each word occurs in the data\n",
    "    # 2. Sort the words by their frequency, in descending order\n",
    "    # 3. Make a list of the special tokens plus the most frequent words, up to a length of `max_size`.\n",
    "    # 4. Return the list\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zmr7Oe9cCus7"
   },
   "source": [
    "With this function, we can construct vocabularies containing the 5,000 most frequent words as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "onyml-oDCus7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_vocab = make_vocab(sentences('en-sv-train.txt', SWEDISH), 5000)\n",
    "tgt_vocab = make_vocab(sentences('en-sv-train.txt', ENGLISH), 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX9T47dnCus8"
   },
   "source": [
    "#### ü§û Test your code\n",
    "\n",
    "To test your code, check that each vocabulary contains 5,000 words, and includes the pseudowords at the right positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tZBil9ezCus8",
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good!\n"
     ]
    }
   ],
   "source": [
    "def test1():\n",
    "    assert len(src_vocab) == 5000\n",
    "    assert len(tgt_vocab) == 5000\n",
    "    assert src_vocab[:4] == ['<pad>', '<unk>', '<bos>', '<eos>']\n",
    "    assert tgt_vocab[:4] == ['<pad>', '<unk>', '<bos>', '<eos>']\n",
    "    print(\"All good!\")\n",
    "\n",
    "test1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap the vocabularies in StringLookup layers\n",
    "\n",
    "For mapping tokens to their vocabulary IDs, we can use Keras' `StringLookup` layer. The next cell constructs layers for both the source and target vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "string_lookup_args = dict(output_mode=\"int\", mask_token=\"<pad>\", oov_token=\"<unk>\")\n",
    "src_lookup = layers.StringLookup(vocabulary=src_vocab, **string_lookup_args)\n",
    "tgt_lookup = layers.StringLookup(vocabulary=tgt_vocab, **string_lookup_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell gives an example how these `StringLookup` layers can be used. Note that the layers already return *tensors*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([   5 1005   11  530  188    4], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "example = \"i returned to japan yesterday .\".split()\n",
    "print(tgt_lookup(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ü§î Task 2: Sanity-check that these numbers are correct\n",
    "\n",
    "Check your understanding of what's happening in the `StringLookup` layer by writing two lines of code:\n",
    "1. One that prints the token corresponding to the _second integer_ in the tensor above.\n",
    "2. One that prints the integer corresponding to the _second word_ (\"returned\") in the example above.\n",
    "\n",
    "Use `tgt_vocab` directly for that, not the lookup layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token corresponding to integer 1005 is: returned\n",
      "The integer corresponding to the \"returned\" is: 1005\n"
     ]
    }
   ],
   "source": [
    "print(f'The token corresponding to integer 1005 is: {tgt_vocab[1005]}')\n",
    "print(f'The integer corresponding to the \"returned\" is: {tgt_vocab.index(\"returned\")}')\n",
    "\n",
    "\n",
    "## TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2fQzgkPCus9"
   },
   "source": [
    "### Wrapping everything in data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MF4JRJVCus9"
   },
   "source": [
    "The next cell defines a function that wraps our dataset in TensorFlow's [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) API, which represents map-style datasets. The advantage of this is that it lets us use standard infrastructure related to the loading and automatic batching of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TkFTb0LkCus9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def append_eos(tensor):\n",
    "    \"Helper function that appends '<eos>' to a sequence.\"\n",
    "    return tf.concat([tensor, tf.constant([\"<eos>\"], dtype=tf.string)], axis=0)\n",
    "\n",
    "def load_translation_dataset(src_lookup, tgt_lookup, filename):\n",
    "    # Build source dataset and convert with src_lookup\n",
    "    src_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        tf.ragged.constant(list(sentences(filename, SWEDISH)))\n",
    "    )\n",
    "    src_dataset = src_dataset.map(src_lookup)\n",
    "\n",
    "    # Build target dataset, append <eos> and convert with tgt_lookup\n",
    "    tgt_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        tf.ragged.constant(list(sentences(filename, ENGLISH)))\n",
    "    )\n",
    "    tgt_dataset = tgt_dataset.map(append_eos).map(tgt_lookup)\n",
    "    \n",
    "    # Zip them together\n",
    "    return tf.data.Dataset.zip((src_dataset, tgt_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnPlzxWrCus-"
   },
   "source": [
    "We load the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "t1tyWbfbCus-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = load_translation_dataset(src_lookup, tgt_lookup, \"en-sv-train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoUAW-GcCus_"
   },
   "source": [
    "The following function can be helpful for debugging. It extracts a single source‚Äìtarget pair of sentences from the specified *dataset* and converts it into batches of size&nbsp;1, which can be fed into the encoder‚Äìdecoder model. This also illustrates how the `Dataset` API works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DC2j_oZyCus_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def example(dataset, i):\n",
    "    if i > 0:\n",
    "        dataset = dataset.skip(i-1)\n",
    "    return list(dataset.take(1).batch(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dYhTBym7Cus_",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[  6  10 245  15  20   7]], shape=(1, 6), dtype=int64)\n",
      "tf.Tensor([[ 29   9 477  55  28   8   3]], shape=(1, 7), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "x, y = example(train_dataset, 42)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw62gfhdCutA"
   },
   "source": [
    "## Part 2: The encoder‚Äìdecoder architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB280fFjCutA"
   },
   "source": [
    "In this section, you will implement the encoder‚Äìdecoder architecture, including the extension of that architecture by an attention mechanism. The implementation consists of four parts: the encoder, the attention mechanism, the decoder, and a class that wraps the complete architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUFFRKwGCutA"
   },
   "source": [
    "### Part 2.1: Implement the encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKeHOZyxCutA"
   },
   "source": [
    "The encoder is a component that takes an input tensor of vocabulary IDs, like the `x` tensor from the example above, and performs the following steps:\n",
    "\n",
    "1. Look up **word embeddings** for each token in the sequence.\n",
    "2. Process them with a **bi-directional recurrent neural network**. This works with any type of RNN, but we will use **GRU (gated recurrent unit) layers** throughout this laboration.\n",
    "3. Feed the output through a linear layer. We also take the last hidden state of the forward GRU and the last hidden state of the backward GRU, concatenate them, and pass them through a linear layer. This produces a \"summary\" of the source sentence, which we will later feed into the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the encoder by defining it as a **custom Keras layer.** For this, we have to define a class that subclasses from `keras.layers.Layer`, instantiate all required model weights and/or (sub)layers in the `__init__()` function, and uses them to perform the layer's computation in the `call()` function. Below is some skeleton code to get you started; you can also [read more about making custom layers in the Keras Docs](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ü§î Task 3: Implement the encoder by completing the skeleton code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "klNT7vTPCutB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, num_words, embedding_dim=128, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        # TODO: Add your code here that defines the required layers/weights\n",
    "        self.embedding = layers.Embedding(input_dim = num_words, output_dim = embedding_dim, mask_zero = True)\n",
    "        self.rnn = layers.Bidirectional(layers.GRU(units = 2*hidden_dim, return_sequences = True, return_state = True))\n",
    "        self.linear = layers.Dense(hidden_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # TODO\n",
    "        # 1. Look up the embeddings for the source words\n",
    "        x = self.embedding(inputs)\n",
    "        # 2. Apply a bi-directional GRU over the source sequences\n",
    "        lastOutput, forwardState, backwardState  = self.rnn(x)\n",
    "        # 3. Apply a linear transformation to the GRU's output\n",
    "        output = self.linear(lastOutput)\n",
    "        # 4. Concatenate forward + backward hidden states and apply a linear transformation on them too\n",
    "        concatenateState = keras.layers.Concatenate(axis=1)([forwardState, backwardState])\n",
    "        hidden = self.linear(concatenateState)\n",
    "        \n",
    "        return(output, hidden)\n",
    "        \n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut1QP_1hCutB"
   },
   "source": [
    "Your code must comply with the following specification:\n",
    "\n",
    "**__init__** (*num_words*, *embedding_dim* = 128, *hidden_dim* = 256)\n",
    "\n",
    "> Initialises the encoder. The encoder consists of an embedding layer that maps each of *num_words* words to an embedding vector of size *embedding_dim*, a bidirectional GRU that maps each embedding vector to a position-specific representation of size 2 √ó *hidden_dim*, and a final linear layer that projects these representations to new representations of size *hidden_dim*.\n",
    "\n",
    "**call** (*self*, *inputs*)\n",
    "\n",
    "> Takes a tensor *inputs* with source-language word ids and sends it through the encoder. The input tensor has shape (*batch_size*, *src_len*), where *src_len* is the length of the sentences in the batch. (We will make sure that all sentences in the same batch have the same length.) The method returns a pair of tensors (*output*, *hidden*), where *output* has shape (*batch_size*, *src_len*, *hidden_dim*), and *hidden* has shape (*batch_size*, *hidden_dim*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xybpq39KCutC"
   },
   "source": [
    "#### ü§û Test your code\n",
    "\n",
    "To test your code, instantiate an encoder, feed it the first source sentence in the training data, and check that the tensors returned by the encoder have the expected shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "LU4SIh0NCutC",
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 256)\n",
      "(1, 256)\n"
     ]
    }
   ],
   "source": [
    "def test21():\n",
    "    src, tgt = example(train_dataset, 42)\n",
    "    encoder = Encoder(src_lookup.vocabulary_size())\n",
    "    output, hidden = encoder(src)\n",
    "    print(output.shape)  # should be (batch_size, src_len, hidden_dim)\n",
    "    print(hidden.shape)  # should be (batch_size, hidden_dim)\n",
    "\n",
    "test21()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnD4At5uCutD"
   },
   "source": [
    "### Part 2.2: Implement the attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twmxl69tCutD"
   },
   "source": [
    "Your next task is to implement the attention mechanism. Recall that the purpose of this mechanism is to inform the decoder when generating the translation of the next word. For this, attention has access to the previous hidden state of the decoder, as well as the complete output of the encoder. It returns the attention-weighted sum of the encoder output, the so-called *context* vector. For later usage, we also return the attention weights.\n",
    "\n",
    "As mentioned in the lecture, attention can be implemented in various ways. One very simple implementation is *uniform attention*, which assigns equal weight to each position-specific representation in the output of the encoder, and completely ignores the hidden state of the decoder. This mechanism is implemented in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "VK4LsCUfCutD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UniformAttention(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, decoder_hidden, encoder_output, mask=None):\n",
    "        # Set all attention scores to the same constant value (0). After\n",
    "        # the softmax, we will have uniform weights.\n",
    "        scores = tf.zeros_like(encoder_output[:, :, -1])\n",
    "        \n",
    "        # Mask out the attention scores for the padding tokens. We set\n",
    "        # them to -inf. After the softmax, we will have 0.\n",
    "        if mask is not None:\n",
    "            masked_value = -float('inf') * tf.ones_like(scores)\n",
    "            scores = tf.where(mask, scores, masked_value)\n",
    "        \n",
    "        # Convert scores into weights\n",
    "        alpha = tf.nn.softmax(scores, axis=1)\n",
    "        \n",
    "        # The context is the alpha-weighted sum of the encoder outputs.\n",
    "        context = tf.linalg.matmul(tf.expand_dims(alpha, axis=1), encoder_output)\n",
    "        context = tf.squeeze(context, axis=1)\n",
    "        \n",
    "        return alpha, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noYs0hSHCutE"
   },
   "source": [
    "One technical detail in this code is our use of *mask* to compute attention weights only for the ‚Äòreal‚Äô tokens in the source sentences, but not for the padding tokens that we introduce to bring all sentences in a batch to the same length.\n",
    "\n",
    "Your task now is to implement the attention mechanism from the paper by [Bahdanau et al. (2015)](https://arxiv.org/abs/1409.0473). The relevant equation is in Section&nbsp;A.1.2:\n",
    "\n",
    "$$\n",
    "a(s_{i-1}, h_j) = v^{\\top} \\tanh(W s_{i-1} + U h_j)\n",
    "$$\n",
    "\n",
    "This equation specifies how to compute the attention score (a scalar) for the previous hidden state of the decoder, denoted by $s_{i-1}$, and the $j$-th position-specific representation in the output of the encoder, denoted by $h_j$. The equation refers to three parameters: a vector $v$ and $W$ and $U$. In PyTorch, these parameters can be represented in terms of (bias-free) linear layers that are trained along with the other parameters of the model.\n",
    "\n",
    "Here is the skeleton code for this problem. As you can see, your specific task is to initialise the required parameters and to compute the attention scores (*scores*); the rest of the code is the same as for the uniform attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ü§î Task 4: Implement Bahdanau attention by completing the skeleton code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "RyclW2osCutE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(layers.Layer):\n",
    "    def __init__(self, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.supports_masking = True\n",
    "        # TODO: Add your code here that defines the required layers/weights\n",
    "        self.w = layers.Dense(hidden_dim, use_bias = False)\n",
    "        self.u = layers.Dense(hidden_dim, use_bias = False)\n",
    "        self.v = layers.Dense(1, use_bias = False)\n",
    "\n",
    "    def call(self, decoder_hidden, encoder_output, mask=None):\n",
    "        # TODO: Replace the next line with your own code that computes the attention scores\n",
    "        \n",
    "        Uh = self.u(encoder_output)\n",
    "        Ws = self.w(tf.expand_dims(decoder_hidden, axis = 1))\n",
    "        \n",
    "        scores = self.v(tf.nn.tanh(Ws + Uh))\n",
    "        scores = tf.squeeze(scores, axis = 2)\n",
    "\n",
    "        # ... The rest of the code is as in UniformAttention ‚Äî NO NEED TO MODIFY BELOW THIS LINE!\n",
    "\n",
    "        # Mask out the attention scores for the padding tokens. We set\n",
    "        # them to -inf. After the softmax, we will have 0.\n",
    "        if mask is not None:\n",
    "            masked_value = -float('inf') * tf.ones_like(scores)\n",
    "            scores = tf.where(mask, scores, masked_value)\n",
    "        \n",
    "        # Convert scores into weights\n",
    "        alpha = tf.nn.softmax(scores, axis=1)\n",
    "        \n",
    "        # The context is the alpha-weighted sum of the encoder outputs.\n",
    "        context = tf.linalg.matmul(tf.expand_dims(alpha, axis=1), encoder_output)\n",
    "        context = tf.squeeze(context, axis=1)\n",
    "        \n",
    "        return alpha, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTB0RPfDCutF"
   },
   "source": [
    "Your code must comply with the following specification:\n",
    "\n",
    "**call** (*decoder_hidden*, *encoder_output*, *mask*)\n",
    "\n",
    "> Takes the previous hidden state of the decoder (*decoder_hidden*) and the encoder output (*encoder_output*) and returns a pair (*alpha*, *context*) where *context* is the context as computed as in [Bahdanau et al. (2015)](https://arxiv.org/abs/1409.0473), and *alpha* are the corresponding attention weights. The hidden state has shape (*batch_size*, *hidden_dim*), the encoder output has shape (*batch_size*, *src_len*, *hidden_dim*), the context has shape (*batch_size*, *hidden_dim*), and the attention weights have shape (*batch_size*, *src_len*).\n",
    "\n",
    "#### üí° Hints on the implementation\n",
    "\n",
    "You may need a few more \"low-level\" TensorFlow functions to implement this part, concretely:\n",
    "    \n",
    "- `tf.expand_dims()` and `tf.squeeze()` to add/remove a dimension from a tensor. This is because some tensors have a \"timestep\" dimension while others (e.g. the hidden state of the decoder) don't.\n",
    "- `tf.nn.tanh()` to compute the $\\tanh$ function on a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxNwwlmuCutF"
   },
   "source": [
    "#### ü§û Test your code\n",
    "\n",
    "To test your code, extend your test from Task 3: Feed the output of your encoder into your attention class. As the previous hidden state of the decoder, you can use the hidden state returned by the encoder. Later, you don't need to pass the mask explicitly (Keras will do this automatically), but for testing purposes, you can obtain the mask from a layer's output via `output._keras_mask`.\n",
    "\n",
    "Check that the context tensor and the attention weights returned by the attention class have the expected shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "ZUqLpHXiCutG",
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n",
      "(1, 256)\n"
     ]
    }
   ],
   "source": [
    "def test22():\n",
    "    src, tgt = example(train_dataset, 42)\n",
    "    encoder = Encoder(src_lookup.vocabulary_size())\n",
    "    output, hidden = encoder(src)\n",
    "    attention = BahdanauAttention()\n",
    "    alpha, context = attention(hidden, output, mask=output._keras_mask)\n",
    "    print(alpha.shape)    # should be (batch_size, src_len)\n",
    "    print(context.shape)  # should be (batch_size, hidden_dim)\n",
    "\n",
    "test22()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fB2A4Qa1CutG"
   },
   "source": [
    "### Part 2.3: Implement the decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AO_4A4XXCutH"
   },
   "source": [
    "Now you are ready to implement the decoder. Like the encoder, the decoder is based on a GRU; but this time we use a unidirectional network, as we generate the target sentences left-to-right.\n",
    "\n",
    "**‚ö†Ô∏è We expect that solving this problem will take you the longest time in this lab.**\n",
    "\n",
    "Because the decoder is an autoregressive model, we need to unroll the GRU \"manually\": At each position, we take the previous hidden state as well as the new input, and apply the GRU for one step. The initial hidden state comes from the encoder. The new input is the embedding of the previous word, concatenated with the context vector from the attention model. To produce the final output, we take the output of the GRU, concatenate the embedding vector and the context vector (residual connection), and feed the result into a linear layer. Here is a graphical representation:\n",
    "\n",
    "<img src=\"https://gitlab.liu.se/nlp/nlp-course/-/raw/master/labs/l3/decoder.svg\" width=\"50%\" alt=\"Decoder architecture\"/>\n",
    "\n",
    "We need to implement this manual unrolling for two very similar tasks: When *training*, both the inputs to and the target outputs of the GRU come from the training data. When *decoding*, the outputs of the GRU are used to generate new target-side words, and these words become the inputs to the next step of the unrolling. **We have already implemented the `call` method that handles both these two different modes of usage ‚Äî you don't need to modify this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ü§î Task 5: Implement the `step` method that takes a single step with the GRU\n",
    "\n",
    "You will also need to add any necessary layers/weights that you use in the `__init__` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "xBDjsJ-1CutH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, trg_lookup, attention, embedding_dim=128, hidden_dim=256, max_len=16):\n",
    "        super().__init__()\n",
    "        num_words = trg_lookup.vocabulary_size()\n",
    "        self.embedding = layers.Embedding(num_words, embedding_dim, mask_zero=True)\n",
    "        self.bos_index = trg_lookup([\"<bos>\"]).numpy()\n",
    "        self.max_len = max_len\n",
    "        # TODO: Add your code here that defines the required layers/weights\n",
    "        self.attention = BahdanauAttention()\n",
    "        self.rnn_cell = layers.GRUCell(units = hidden_dim)\n",
    "        self.linear = layers.Dense(hidden_dim)\n",
    "\n",
    "    def call(self, encoder_output, initial_state, targets=None, training=False, mask=None):\n",
    "        # YOU WON'T NEED TO MODIFY ANYTHING IN THIS FUNCTION.\n",
    "\n",
    "        if training:\n",
    "            assert targets is not None\n",
    "\n",
    "        # Initialise the hidden state from `initial_state`\n",
    "        state = initial_state\n",
    "        \n",
    "        # Initialise the decoder input with the `<bos>` symbol\n",
    "        next_input = self.bos_index * tf.ones_like(initial_state, dtype=tf.int64)\n",
    "        next_input = next_input[:, 0]\n",
    "        \n",
    "        # Initialise the list of outputs and attention weights\n",
    "        outputs = tf.TensorArray(\n",
    "            tf.float32,\n",
    "            size=0 if training else self.max_len,\n",
    "            dynamic_size=training,\n",
    "        )\n",
    "        alphas = tf.TensorArray(\n",
    "            tf.float32,\n",
    "            size=0 if training else self.max_len,\n",
    "            dynamic_size=training,\n",
    "        )\n",
    "        inputs = tf.TensorArray(\n",
    "            tf.int64,\n",
    "            size=0 if training else self.max_len,\n",
    "            dynamic_size=training,\n",
    "        )\n",
    "\n",
    "        # In training mode, we iterate over the length of the target sentences,\n",
    "        # otherwise we iterate until `self.max_len` is reached\n",
    "        max_len = tf.shape(targets)[1] if training else self.max_len\n",
    "        \n",
    "        for i in range(max_len):\n",
    "            # In training mode, we feed the correct (gold) predictions as the next input\n",
    "            if training and i > 0:\n",
    "                next_input = targets[:, i-1]\n",
    "            \n",
    "            # Get the embedding for the previous word\n",
    "            prev_embed = self.embedding(next_input)\n",
    "            \n",
    "            # Take one step with the RNN\n",
    "            step_output, state, alpha = self.step(encoder_output, state, prev_embed, mask=mask)\n",
    "            \n",
    "            # Update the list of generated words and attention weights\n",
    "            outputs = outputs.write(i, step_output)\n",
    "            alphas = alphas.write(i, alpha)\n",
    "            inputs = inputs.write(i, next_input)\n",
    "\n",
    "            # Set the prediction with highest probability as the input for the next timestep\n",
    "            if not training:\n",
    "                next_input = tf.math.argmax(step_output, axis=-1)\n",
    "\n",
    "        # Lists of outputs and attention weights are [tgt_len, batch_size, *],\n",
    "        # so we transpose them to have the batch dimension in first place again.\n",
    "        outputs = tf.transpose(outputs.stack(), perm=[1,0,2])\n",
    "        alphas = tf.transpose(alphas.stack(), perm=[1,0,2])\n",
    "        inputs = tf.transpose(inputs.stack(), perm=[1,0])\n",
    "        outputs._keras_mask = (inputs != 0)\n",
    "        \n",
    "        return outputs, alphas\n",
    "    \n",
    "    def step(self, encoder_output, hidden_state, prev_embed, mask=None):\n",
    "        # TODO: Replace the next line with your own code; this should follow the illustration above.\n",
    "        # 1. Get the attention weights and context vector\n",
    "\n",
    "        alpha, context = self.attention(hidden_state, encoder_output, mask)\n",
    "  \n",
    "        # 2. Concatenate the inputs for the GRU\n",
    "       # print(context.shape)\n",
    "       # print(prev_embed.shape)\n",
    "        rnn_input = keras.layers.Concatenate(axis=1)([prev_embed, context])\n",
    "        # 3. Take one step with the GRU cell\n",
    "        rnn_output, hidden_state = self.rnn_cell(rnn_input, hidden_state)\n",
    "        # 4. Concatenate the respective tensors to produce the final output\n",
    "        output = keras.layers.Concatenate(axis=1)([rnn_input, rnn_output])\n",
    "        \n",
    "        return output, hidden_state, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ej2-lzyVCutH"
   },
   "source": [
    "Your implementation should comply with the following specification:\n",
    "\n",
    "**step** (*self*, *encoder_output*, *hidden*, *prev_embed*, *mask*)\n",
    "\n",
    "> Performs a single step in the manual unrolling of the decoder GRU. This takes the output of the encoder (*encoder_output*), the previous hidden state of the decoder (*hidden*), the embedding vector of the previous word (*prev_embed*), and the source mask as described in Problem&nbsp;2.2 (*mask*), and computes the output as described above.\n",
    ">\n",
    "> The shape of *encoder_output* is (*batch_size*, *src_len*, *hidden_dim*); the shape of *hidden* is (*batch_size*, *hidden_dim*); the shape of *src_mask* is (*batch_size*, *src_len*); and the shape of *prev_embed* is (*batch_size*, *embedding_dim*).\n",
    ">\n",
    "> The method returns a triple of tensors (*output*, *hidden*, *alpha*) where *output* is the position-specific output of the GRU, of shape (*batch_size*, *num_words*); *hidden* is the new hidden state, of shape (*batch_size*, *hidden_dim*); and *alpha* are the attention weights that were used to compute the *output*, of shape (*batch_size*, *src_len*).\n",
    "\n",
    "#### üí° Hints on the implementation\n",
    "\n",
    "**GRU vs. GRUCell.** In Keras, an RNN layer like `GRU` is used to process an entire sequence. A single *time-step* of a sequence is handled by a [`GRUCell`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell) instead. You can think of a `GRU` layer as functionally equivalent to a for-loop around a `GRUCell`. Since we want to perform the RNN steps individually for this model, you should use a [`GRUCell`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell) instead of a `GRU` layer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFvNiX-YCutI"
   },
   "source": [
    "#### ü§û Test your code\n",
    "\n",
    "To test your code, extend your test from the previous problems, and simulate a complete forward pass of the encoder‚Äìdecoder architecture on the example sentence. Check the shapes of the resulting tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "65lLG-bBCutI",
    "scrolled": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'bahdanau_attention_54' (type BahdanauAttention).\n\n{{function_node __wrapped__Squeeze_device_/job:localhost/replica:0/task:0/device:CPU:0}} Can not squeeze dim[0], expected a dimension of 1, got 4 [Op:Squeeze]\n\nCall arguments received by layer 'bahdanau_attention_54' (type BahdanauAttention):\n  ‚Ä¢ decoder_hidden=tf.Tensor(shape=(4, 256), dtype=float32)\n  ‚Ä¢ encoder_output=tf.Tensor(shape=(4, 5, 256), dtype=float32)\n  ‚Ä¢ mask=tf.Tensor(shape=(4, 5), dtype=bool)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     decoded, _ \u001b[38;5;241m=\u001b[39m decoder(encoder_output, hidden, targets\u001b[38;5;241m=\u001b[39mtgt, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(decoded\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# should be (batch_size, tgt_len, vocabulary_size)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtest23\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[145], line 7\u001b[0m, in \u001b[0;36mtest23\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m attention \u001b[38;5;241m=\u001b[39m BahdanauAttention()\n\u001b[1;32m      6\u001b[0m decoder \u001b[38;5;241m=\u001b[39m Decoder(tgt_lookup, attention)\n\u001b[0;32m----> 7\u001b[0m decoded, alphas \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(decoded\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# should be (batch_size, max_len, vocabulary_size)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(alphas\u001b[38;5;241m.\u001b[39mshape)   \u001b[38;5;66;03m# should be (batch_size, max_len, src_len)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[144], line 56\u001b[0m, in \u001b[0;36mDecoder.call\u001b[0;34m(self, encoder_output, initial_state, targets, training, mask)\u001b[0m\n\u001b[1;32m     53\u001b[0m prev_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(next_input)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Take one step with the RNN\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m step_output, state, alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Update the list of generated words and attention weights\u001b[39;00m\n\u001b[1;32m     59\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mwrite(i, step_output)\n",
      "Cell \u001b[0;32mIn[144], line 80\u001b[0m, in \u001b[0;36mDecoder.step\u001b[0;34m(self, encoder_output, hidden_state, prev_embed, mask)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoder_output, hidden_state, prev_embed, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# TODO: Replace the next line with your own code; this should follow the illustration above.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# 1. Get the attention weights and context vector\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     alpha, context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# 2. Concatenate the inputs for the GRU\u001b[39;00m\n\u001b[1;32m     83\u001b[0m    \u001b[38;5;66;03m# print(context.shape)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m    \u001b[38;5;66;03m# print(prev_embed.shape)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     rnn_input \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConcatenate(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)([prev_embed, context])\n",
      "Cell \u001b[0;32mIn[142], line 17\u001b[0m, in \u001b[0;36mBahdanauAttention.call\u001b[0;34m(self, decoder_hidden, encoder_output, mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m Ws \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw(tf\u001b[38;5;241m.\u001b[39mexpand_dims(decoder_hidden, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     16\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv(tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mtanh(Ws \u001b[38;5;241m+\u001b[39m Uh))\n\u001b[0;32m---> 17\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# ... The rest of the code is as in UniformAttention ‚Äî NO NEED TO MODIFY BELOW THIS LINE!\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Mask out the attention scores for the padding tokens. We set\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# them to -inf. After the softmax, we will have 0.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'bahdanau_attention_54' (type BahdanauAttention).\n\n{{function_node __wrapped__Squeeze_device_/job:localhost/replica:0/task:0/device:CPU:0}} Can not squeeze dim[0], expected a dimension of 1, got 4 [Op:Squeeze]\n\nCall arguments received by layer 'bahdanau_attention_54' (type BahdanauAttention):\n  ‚Ä¢ decoder_hidden=tf.Tensor(shape=(4, 256), dtype=float32)\n  ‚Ä¢ encoder_output=tf.Tensor(shape=(4, 5, 256), dtype=float32)\n  ‚Ä¢ mask=tf.Tensor(shape=(4, 5), dtype=bool)"
     ]
    }
   ],
   "source": [
    "def test23():\n",
    "    src, tgt = list(train_dataset.take(4).padded_batch(4))[0]\n",
    "    encoder = Encoder(src_lookup.vocabulary_size())\n",
    "    encoder_output, hidden = encoder(src)\n",
    "    attention = BahdanauAttention()\n",
    "    decoder = Decoder(tgt_lookup, attention)\n",
    "    decoded, alphas = decoder(encoder_output, hidden)\n",
    "    print(decoded.shape)  # should be (batch_size, max_len, vocabulary_size)\n",
    "    print(alphas.shape)   # should be (batch_size, max_len, src_len)\n",
    "    decoded, _ = decoder(encoder_output, hidden, targets=tgt, training=True)\n",
    "    print(decoded.shape)  # should be (batch_size, tgt_len, vocabulary_size)\n",
    "\n",
    "test23()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70yHTFS9CutJ"
   },
   "source": [
    "### Encoder‚ÄìDecoder wrapper class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeKfvES5CutJ"
   },
   "source": [
    "The last part of the implementation is a class that wraps the encoder and the decoder as a single model.  We also implement a custom `train_step` function so that the gold targets will get passed to the decoder during training, and a custom `test_step` function to make sure the decoded sequences and the gold sequences are padded to the same length before computing losses and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "lUjIGniZCutJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(keras.Model):\n",
    "    def __init__(self, src_lookup, tgt_lookup, embedding_dim=128, hidden_dim=256, max_len=16, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = Encoder(\n",
    "            src_lookup.vocabulary_size(),\n",
    "            embedding_dim=embedding_dim,\n",
    "            hidden_dim=hidden_dim\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            tgt_lookup,\n",
    "            BahdanauAttention(hidden_dim=hidden_dim),\n",
    "            embedding_dim=embedding_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            max_len=max_len,\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs, training=False, targets=None):\n",
    "        x_out, x_hidden = self.encoder(inputs, training=training)\n",
    "        outputs, alphas = self.decoder(x_out, x_hidden, training=training, targets=targets)\n",
    "        if training:\n",
    "            return outputs\n",
    "        else:\n",
    "            return outputs, alphas\n",
    "    \n",
    "    # Following <https://keras.io/guides/customizing_what_happens_in_fit/>\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Here we supply \"targets\" so that the decoder has access to it\n",
    "            y_pred = self(x, training=True, targets=y)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        \n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred, _alphas = self(x, training=False)\n",
    "\n",
    "        # Pad sequences to the same number of time-steps\n",
    "        max_len = tf.math.maximum(tf.shape(y)[1], tf.shape(y_pred)[1])\n",
    "        y_pad = [[0, 0], [0, max_len - tf.shape(y)[1]]]\n",
    "        y = tf.pad(y, y_pad)\n",
    "        y_pred_pad = [[0, 0], [0, max_len - tf.shape(y_pred)[1]], [0, 0]]\n",
    "        y_pred = tf.pad(y_pred, y_pred_pad)\n",
    "            \n",
    "        self.compute_loss(x, y, y_pred, None)\n",
    "        return self.compute_metrics(x, y, y_pred, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3uW3TKACutK"
   },
   "source": [
    "#### ü§û Test your code\n",
    "\n",
    "As a final test, instantiate an encoder‚Äìdecoder model and use it to decode the example sentence. Check the shapes of the resulting tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "oO6zONDwCutK",
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 640)\n",
      "(1, 16, 6)\n"
     ]
    }
   ],
   "source": [
    "def test24():\n",
    "    src, tgt = example(train_dataset, 42)\n",
    "    encoder_decoder = EncoderDecoder(src_lookup, tgt_lookup)\n",
    "    outputs, alphas = encoder_decoder(src)\n",
    "    print(outputs.shape)  # should be (batch_size, max_len, vocabulary_size)\n",
    "    print(alphas.shape)   # should be (batch_size, max_len, src_len)\n",
    "\n",
    "test24()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laK9bbq8CutL"
   },
   "source": [
    "## Part 3: Train a translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q68aWc_2CutL"
   },
   "source": [
    "We now have all the pieces to build and train a complete translation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5MYw2PJCutL"
   },
   "source": [
    "### Translator class\n",
    "\n",
    "We first define a class `Translator` that initialises an encoder‚Äìdecoder model and uses it to translate sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "Evi-J7BfCutM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    def __init__(self, src_lookup, tgt_lookup, batch_size=32, **kwargs):\n",
    "        self.src_lookup = src_lookup\n",
    "        self.tgt_lookup = tgt_lookup\n",
    "        self.model = EncoderDecoder(src_lookup, tgt_lookup, **kwargs)\n",
    "        self.tgt_vocab = tgt_lookup.get_vocabulary()\n",
    "        self.eos_index = self.tgt_vocab.index(\"<eos>\")\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        return self.model.compile(*args, **kwargs)\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self.model.fit(*args, **kwargs)\n",
    "\n",
    "    def translate(self, sentences, return_alphas=False):\n",
    "        \"\"\"This function takes sentences and returns their translation as a string.\n",
    "        \n",
    "        `sentences` can be either:\n",
    "          - A tf.data.Dataset object\n",
    "          - A list of strings\n",
    "        \"\"\"\n",
    "        if isinstance(sentences, tf.data.Dataset):\n",
    "            inputs = sentences\n",
    "        elif isinstance(sentences, (list, tuple)):\n",
    "            inputs = (\n",
    "                tf.data.Dataset.from_tensor_slices(\n",
    "                    tf.ragged.constant([x.split() for x in sentences])\n",
    "                )\n",
    "                .map(self.src_lookup)\n",
    "                .padded_batch(min(self.batch_size, len(sentences)))\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"'sentences' should be either a tf.Dataset or a list of strings; got: {type(sentences)}\")\n",
    "\n",
    "        outputs, alphas = self.model.predict(inputs, verbose=0)\n",
    "        outputs = tf.math.argmax(outputs, axis=-1).numpy().tolist()\n",
    "        try:\n",
    "            alphas = alphas.numpy().tolist()\n",
    "        except AttributeError:\n",
    "            alphas = alphas.tolist()\n",
    "        generated = []\n",
    "\n",
    "        for y_pred, alpha in zip(outputs, alphas):\n",
    "            try:\n",
    "                eos_idx = y_pred.index(self.eos_index)\n",
    "                del y_pred[eos_idx:]\n",
    "                del alpha[eos_idx:]\n",
    "            except ValueError:\n",
    "                pass\n",
    "            tokens = [self.tgt_vocab[idx] for idx in y_pred if idx > 0]\n",
    "            tokens = \" \".join(tokens)\n",
    "            if return_alphas:\n",
    "                generated.append((tokens, alpha))\n",
    "            else:\n",
    "                generated.append(tokens)\n",
    "\n",
    "        return generated\n",
    "        \n",
    "    def translate_with_attention(self, sentences):\n",
    "        return self.translate(sentences, return_alphas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2660iyt-CutN"
   },
   "source": [
    "The code below shows how this class is supposed to be used (its output will be nonsensical right now, of course, since the model hasn't been trained yet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "NFiJLKRXCutN",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eat can said really in take a from they give been have all this could that',\n",
       " 'eat can said really in take a from they give been have all this could that']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = Translator(src_lookup, tgt_lookup)\n",
    "# Alternative \"mini\" version of the model for testing:\n",
    "#translator = Translator(src_lookup, tgt_lookup, embedding_dim=32, hidden_dim=64, batch_size=16, max_len=8)\n",
    "translator.translate(['st√§ng av vattnet .', 'jag √§lskar friterade bananer .'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cFT9atlCutO"
   },
   "source": [
    "### Evaluation function\n",
    "\n",
    "As mentioned in the lecture, machine translation systems are typically evaluated using the **BLEU metric**. Here we use the implementation of this metric from the `sacrebleu` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "bleu_params = dict(effective_order=True, tokenize=\"none\", force=True, smooth_method=\"floor\", smooth_value=0.01)\n",
    "bleu = BLEU(**bleu_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the test sentence is exactly identical to the reference sentence, the score will be 100 (plus/minus potential floating point rounding errors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.00000000000004"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_score(\"the house is blue .\", [\"the house is blue .\"]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change some words, the score will go down, though never below zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9763536438352522"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_score(\"the house was red .\", [\"the house is blue .\"]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a helper function that takes a trained `Translator` model as well as a `Dataset`, runs all sentences through the translator, and computes the BLEU score for the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bleu(translator, dataset):\n",
    "    hyp = translator.translate(dataset)\n",
    "    ref = [\n",
    "        \" \".join(translator.tgt_vocab[idx] for idx in s if idx not in (0, translator.eos_index))\n",
    "        for s in dataset.unbatch().map(lambda _, x: x).as_numpy_iterator()\n",
    "    ]\n",
    "    return bleu.corpus_score(hyp, [ref]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ozk1hurqCutP"
   },
   "source": [
    "We want to report the BLEU score on the **validation data**, so let's load this as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "HNtBMDVqCutP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_dataset = load_translation_dataset(src_lookup, tgt_lookup, \"en-sv-valid.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xe2rPzwmCutQ"
   },
   "source": [
    "### Batching\n",
    "\n",
    "So far we only tested our code on \"batches\" with a single sentence. In order to use larger batches, we need to make sure that all of the sentences in a batch have the same length. We achieve this by _padding_ the shorter sentences to the length of the longest one. Luckily, the `tf.Dataset` class has a function [`padded_batch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#padded_batch) that will do this for us. If we provide a `Dataset` for training, Keras won't shuffle the data automatically, so we also have to [`shuffle`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle) the dataset explicitly. (For validation, shuffling doesn't matter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "X-yfmnSzCutQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batched = train_dataset.shuffle(512).padded_batch(64)\n",
    "valid_batched = valid_dataset.padded_batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfM1Ov-sCutQ"
   },
   "source": [
    "### Training\n",
    "\n",
    "Training works as for any other Keras model: we first need to `compile` the model with the optimizer, loss function, and validation metrics that we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "yr4VP-SpCutQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "translator.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=2e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgXElolrCutR"
   },
   "source": [
    "Now it is time to train the system. During training, these diagnostics will be updated periodically: the running average of the training loss; after a full epoch, the loss and the BLEU score on the validation data will be computed and printed.\n",
    "\n",
    "Let's also define a callback that additionally prints the translation of a sample sentence, *jag saknar min familj* (which should translate into *i miss my family*), every 50 batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    keras.callbacks.LambdaCallback(\n",
    "        on_train_batch_end=lambda b, _: tf.print(\" - jag saknar min familj . ->\", translator.translate(['jag saknar min familj .'])[0]) if b > 0 and b % 50 == 0 else None,\n",
    "        on_epoch_end=lambda _, l: l.__setitem__(\"val_bleu\", compute_bleu(translator, valid_batched))\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ü§î Task 6: Run the model training\n",
    "\n",
    "Run the following code cells that train the model and evaluate it on the validation data.\n",
    "\n",
    "Training the translator takes quite a bit of compute power and time. The default number of epochs is 2; however, you may want to try training for longer, or interrupt the training prematurely and use a partially trained model in case you run out of time.\n",
    "\n",
    "**‚ö†Ô∏è Your submitted notebook must contain output demonstrating at least 20 BLEU points on the validation data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "VW8wF8oRCutR",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_653482/2533460516.py\", line 1, in <module>\n      get_ipython().run_cell_magic('time', '', 'try:\\n    translator.fit(train_batched, epochs=2, validation_data=valid_batched, callbacks=my_callbacks)\\nexcept KeyboardInterrupt:\\n    pass\\n')\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2478, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/magics/execution.py\", line 1325, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 2, in <module>\n    File \"/tmp/ipykernel_653482/304096578.py\", line 14, in fit\n      return self.model.fit(*args, **kwargs)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/tmp/ipykernel_653482/1524211176.py\", line 32, in train_step\n      loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/backend.py\", line 5660, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 3474 which is outside the valid range of [0, 640).  Label values: 5 229 15 188 4 3 0 0 0 0 0 0 0 0 0 0 5 201 15 38 1963 18 9 78 39 152 532 4 3 0 0 0 29 9 477 55 28 8 3 0 0 0 0 0 0 0 0 0 7 186 42 682 10 272 4 3 0 0 0 0 0 0 0 0 15 1697 41 286 4 3 0 0 0 0 0 0 0 0 0 0 1706 35 29 9 349 8 3 0 0 0 0 0 0 0 0 0 5 124 120 15 4 3 0 0 0 0 0 0 0 0 0 0 96 6 16 1501 10 348 578 4 3 0 0 0 0 0 0 0 5 6 32 67 11 22 11 1106 23 4 3 0 0 0 0 0 37 139 17 5 22 11 146 43 8 3 0 0 0 0 0 0 103 536 31 6 14 946 283 1012 4 3 0 0 0 0 0 0 5 127 9 6 102 36 15 4 3 0 0 0 0 0 0 0 1707 10 3474 25 221 4 3 0 0 0 0 0 0 0 0 0 7 716 1109 4 3 0 0 0 0 0 0 0 0 0 0 0 10 137 56 106 826 4 3 0 0 0 0 0 0 0 0 0 54 25 12 651 1222 39 18 109 4 3 0 0 0 0 0 0 5 82 783 9 4 3 0 0 0 0 0 0 0 0 0 0 5 6 102 91 36 11 125 11 9 4 3 0 0 0 0 0 9 22 99 111 11 17 4 3 0 0 0 0 0 0 0 0 19 47 30 117 118 1081 2471 1954 4 3 0 0 0 0 0 0 46 239 28 886 319 4 3 0 0 0 0 0 0 0 0 0 31 6 14 9 45 11 250 26 532 30 10 374 8 3 0 0 7 627 18 6 16 85 261 4 3 0 0 0 0 0 0 0 33 9 438 18 8 3 0 0 0 0 0 0 0 0 0 0 5 6 48 41 1985 39 26 216 534 4 3 0 0 0 0 0 20 2502 1103 4 3 0 0 0 0 0 0 0 0 0 0 0 5 44 10 246 4 3 0 0 0 0 0 0 0 0 0 0 46 229 12 159 55 10 1091 4 3 0 0 0 0 0 0 0 24 6 16 27 10 207 8 3 0 0 0 0 0 0 0 0 19 6 40 42 67 11 41 579 11 227 9 4 3 0 0 0 51 31 6 14 172 9 4 3 0 0 0 0 0 0 0 0 7 273 131 20 25 1229 4 3 0 0 0 0 0 0 0 0 18 628 36 12 85 581 4 3 0 0 0 0 0 0 0 0 37 33 19 287 15 8 3 0 0 0 0 0 0 0 0 0 26 212 13 538 4 3 0 0 0 0 0 0 0 0 0 0 46 95 42 83 537 46 25 787 4 3 0 0 0 0 0 0 5 6 48 120 10 501 4 3 0 0 0 0 0 0 0 0 21 9 335 197 8 3 0 0 0 0 0 0 0 0 0 0 15 397 62 11 41 286 4 3 0 0 0 0 0 0 0 0 5 21 6 14 324 10 127 30 1353 7 98 12 251 4 3 0 77 486 62 4 3 0 0 0 0 0 0 0 0 0 0 0 19 80 11 74 7 4 3 0 0 0 0 0 0 0 0 0 87 28 12 326 423 4 3 0 0 0 0 0 0 0 0 0 5 116 36 7 4 3 0 0 0 0 0 0 0 0 0 0 15 604 11 22 11 126 23 35 187 15 6 16 10 424 4 3 7 6 16 265 149 86 11 49 44 50 230 420 4 3 0 0 5 605 26 3442 4 3 0 0 0 0 0 0 0 0 0 0 5 6 32 42 552 18 4 3 0 0 0 0 0 0 0 0 24 6 16 34 132 6 16 161 8 3 0 0 0 0 0 0 5 80 12 221 77 4 3 0 0 0 0 0 0 0 0 0 5 6 48 287 23 452 4 3 0 0 0 0 0 0 0 0 7 1488 55 10 520 30 50 635 4 3 0 0 0 0 0 0 92 33 9 204 7 8 3 0 0 0 0 0 0 0 0 0 7 71 3426 11 1219 52 12 748 1080 4 3 0 0 0 0 0 7 56 1960 782 1495 4 3 0 0 0 0 0 0 0 0 0 101 18 354 9 45 11 467 64 8 3 0 0 0 0 0 0 29 9 1962 205 8 3 0 0 0 0 0 0 0 0 0 0 24 33 9 478 8 3 0 0 0 0 0 0 0 0 0 0 5 96 7 157 4 3 0 0 0 0 0 0 0 0 0 0 94 9 134 956 10 198 8 3 0 0 0 0 0 0 0 0 10 1972 126 15 25 12 3460 18 7 140 15 881 10 272 4 3 46 6 16 42 43 4 3 0 0 0 0 0 0 0 0 0 68 101 7 1091 8 3 0 0 0 0 0 0 0 0 0 0 5 45 11 409 3470 293 4 3 0 0 0 0 0 0 0 0\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_93616]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "Cell \u001b[0;32mIn[120], line 14\u001b[0m, in \u001b[0;36mTranslator.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_653482/2533460516.py\", line 1, in <module>\n      get_ipython().run_cell_magic('time', '', 'try:\\n    translator.fit(train_batched, epochs=2, validation_data=valid_batched, callbacks=my_callbacks)\\nexcept KeyboardInterrupt:\\n    pass\\n')\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2478, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/IPython/core/magics/execution.py\", line 1325, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 2, in <module>\n    File \"/tmp/ipykernel_653482/304096578.py\", line 14, in fit\n      return self.model.fit(*args, **kwargs)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/tmp/ipykernel_653482/1524211176.py\", line 32, in train_step\n      loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/opt/liu/course-venv-732a78/2/lib/python3.8/site-packages/keras/backend.py\", line 5660, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 3474 which is outside the valid range of [0, 640).  Label values: 5 229 15 188 4 3 0 0 0 0 0 0 0 0 0 0 5 201 15 38 1963 18 9 78 39 152 532 4 3 0 0 0 29 9 477 55 28 8 3 0 0 0 0 0 0 0 0 0 7 186 42 682 10 272 4 3 0 0 0 0 0 0 0 0 15 1697 41 286 4 3 0 0 0 0 0 0 0 0 0 0 1706 35 29 9 349 8 3 0 0 0 0 0 0 0 0 0 5 124 120 15 4 3 0 0 0 0 0 0 0 0 0 0 96 6 16 1501 10 348 578 4 3 0 0 0 0 0 0 0 5 6 32 67 11 22 11 1106 23 4 3 0 0 0 0 0 37 139 17 5 22 11 146 43 8 3 0 0 0 0 0 0 103 536 31 6 14 946 283 1012 4 3 0 0 0 0 0 0 5 127 9 6 102 36 15 4 3 0 0 0 0 0 0 0 1707 10 3474 25 221 4 3 0 0 0 0 0 0 0 0 0 7 716 1109 4 3 0 0 0 0 0 0 0 0 0 0 0 10 137 56 106 826 4 3 0 0 0 0 0 0 0 0 0 54 25 12 651 1222 39 18 109 4 3 0 0 0 0 0 0 5 82 783 9 4 3 0 0 0 0 0 0 0 0 0 0 5 6 102 91 36 11 125 11 9 4 3 0 0 0 0 0 9 22 99 111 11 17 4 3 0 0 0 0 0 0 0 0 19 47 30 117 118 1081 2471 1954 4 3 0 0 0 0 0 0 46 239 28 886 319 4 3 0 0 0 0 0 0 0 0 0 31 6 14 9 45 11 250 26 532 30 10 374 8 3 0 0 7 627 18 6 16 85 261 4 3 0 0 0 0 0 0 0 33 9 438 18 8 3 0 0 0 0 0 0 0 0 0 0 5 6 48 41 1985 39 26 216 534 4 3 0 0 0 0 0 20 2502 1103 4 3 0 0 0 0 0 0 0 0 0 0 0 5 44 10 246 4 3 0 0 0 0 0 0 0 0 0 0 46 229 12 159 55 10 1091 4 3 0 0 0 0 0 0 0 24 6 16 27 10 207 8 3 0 0 0 0 0 0 0 0 19 6 40 42 67 11 41 579 11 227 9 4 3 0 0 0 51 31 6 14 172 9 4 3 0 0 0 0 0 0 0 0 7 273 131 20 25 1229 4 3 0 0 0 0 0 0 0 0 18 628 36 12 85 581 4 3 0 0 0 0 0 0 0 0 37 33 19 287 15 8 3 0 0 0 0 0 0 0 0 0 26 212 13 538 4 3 0 0 0 0 0 0 0 0 0 0 46 95 42 83 537 46 25 787 4 3 0 0 0 0 0 0 5 6 48 120 10 501 4 3 0 0 0 0 0 0 0 0 21 9 335 197 8 3 0 0 0 0 0 0 0 0 0 0 15 397 62 11 41 286 4 3 0 0 0 0 0 0 0 0 5 21 6 14 324 10 127 30 1353 7 98 12 251 4 3 0 77 486 62 4 3 0 0 0 0 0 0 0 0 0 0 0 19 80 11 74 7 4 3 0 0 0 0 0 0 0 0 0 87 28 12 326 423 4 3 0 0 0 0 0 0 0 0 0 5 116 36 7 4 3 0 0 0 0 0 0 0 0 0 0 15 604 11 22 11 126 23 35 187 15 6 16 10 424 4 3 7 6 16 265 149 86 11 49 44 50 230 420 4 3 0 0 5 605 26 3442 4 3 0 0 0 0 0 0 0 0 0 0 5 6 32 42 552 18 4 3 0 0 0 0 0 0 0 0 24 6 16 34 132 6 16 161 8 3 0 0 0 0 0 0 5 80 12 221 77 4 3 0 0 0 0 0 0 0 0 0 5 6 48 287 23 452 4 3 0 0 0 0 0 0 0 0 7 1488 55 10 520 30 50 635 4 3 0 0 0 0 0 0 92 33 9 204 7 8 3 0 0 0 0 0 0 0 0 0 7 71 3426 11 1219 52 12 748 1080 4 3 0 0 0 0 0 7 56 1960 782 1495 4 3 0 0 0 0 0 0 0 0 0 101 18 354 9 45 11 467 64 8 3 0 0 0 0 0 0 29 9 1962 205 8 3 0 0 0 0 0 0 0 0 0 0 24 33 9 478 8 3 0 0 0 0 0 0 0 0 0 0 5 96 7 157 4 3 0 0 0 0 0 0 0 0 0 0 94 9 134 956 10 198 8 3 0 0 0 0 0 0 0 0 10 1972 126 15 25 12 3460 18 7 140 15 881 10 272 4 3 46 6 16 42 43 4 3 0 0 0 0 0 0 0 0 0 68 101 7 1091 8 3 0 0 0 0 0 0 0 0 0 0 5 45 11 409 3470 293 4 3 0 0 0 0 0 0 0 0\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_93616]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    translator.fit(train_batched, epochs=2, validation_data=valid_batched, callbacks=my_callbacks)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_bleu(translator, valid_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ÑπÔ∏è Some notes on the translations\n",
    "\n",
    "If you try out sentences to see their translation (like in the code cell below), you might find some possibly surprising results, such as:\n",
    "\n",
    "- **Translations that are seemingly nonsensical or have nothing to do with the input.** This might be because the model is undertrained; you could try training for more epochs to see if the translations improve. It's also possible that you tried words or phrases that were just not well-represented in the training data.\n",
    "- **Translations that have a lot of `<unk>`s.** This might be due to the words just not being present in the model's vocabulary! Remember you can check this with the vocabularies you created, e.g. `\"friterade\" in src_vocab`. You could try increasing the vocabulary size and see if the results improve, but this will also increase training time.\n",
    "\n",
    "Finally, keep in mind that both the dataset and the model itself is quite tiny, as it's optimized for speed and demonstration purposes rather than efficiency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator.translate(['jag saknar min familj . ', 'st√§ng av vattnet .', 'jag √§lskar friterade bananer .'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7677Q0QLCutS"
   },
   "source": [
    "# Part 4: Visualising attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCzHCB4XCutS"
   },
   "source": [
    "Figure&nbsp;3 in the paper by [Bahdanau et al. (2015)](https://arxiv.org/abs/1409.0473) shows some heatmaps of attention weights in selected sentences. In the last problem of this lab, we ask you to inspect attention weights for your trained translation system. We define a function `plot_attention` that visualises the attention weights. The *x*-axis corresponds to the words in the source sentence (Swedish) and the *y*-axis to the generated target sentence (English).\n",
    "\n",
    "The heatmap colours represent the **strengths of the attention weights**, with _lighter_ cells indicating a _higher_ attention value, just as in the Bahdanau et al. paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXHPiuamCutS"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "def plot_attention(translator, sentence):\n",
    "    translation, weights = translator.translate_with_attention([sentence])[0]\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    heatmap = ax.pcolor(weights, cmap='Blues_r', vmin=0., vmax=1.)\n",
    "\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.set_xticks(np.arange(weights.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(weights.shape[0]) + 0.5, minor=False)\n",
    "    ax.set_xticklabels(sentence.split(), minor=False, rotation=40)\n",
    "    ax.set_yticklabels(translation.split(), minor=False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.colorbar(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGCwchIdCutS"
   },
   "source": [
    "Here is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hj4teeITCutT"
   },
   "outputs": [],
   "source": [
    "plot_attention(translator, 'jag saknar min familj . ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ü§î Task 7: Use these heatmaps to inspect the attention patterns for selected Swedish sentences\n",
    "\n",
    "Try to find sentences for which the model produces reasonably good English translations. If you don't speak Swedish, use sentences from the validation data. It might be interesting to look at examples where the Swedish and the English word order differ substantially.\n",
    "\n",
    "Based on your exploration, **answer the following questions:**\n",
    "\n",
    "- What sentences did you try out? What patterns did you spot? Include example heatmaps in your notebook.\n",
    "- Based on what you know about attention, did you expect your results? Was there anything surprising in them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ü•≥ Congratulations on finishing this lab! ü•≥**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP-L5-WithSolutions.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "12f500e95db8c7000aae6810a3b3f88d1298056c5758c6b1fc4b18ff2c238050"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
